#!/usr/bin/env python

import sys
import glob
import re
import wave
import time
import csv
import sox
import subprocess
import hashlib
from os import path
from tqdm import tqdm


def main():

	paths = ['./']
	if len(sys.argv) > 1:
		paths = sys.argv[1:]

	fieldnames = [
		'path',
		'id',
		'side',
		'dig',
		'take',
		'notes',	
		'channels',
		'sample_rate',
		'bitrate',
		'num_samples',
		'encoding',
		'precision',
		'duration',		
		'size',
		'md5',
		'updated at (UTC)',

	]

	csv_writer = csv.DictWriter(sys.stdout, fieldnames = fieldnames, quoting=csv.QUOTE_MINIMAL)
	csv_writer.writeheader()

	for this_path in paths:
		file_paths = glob.glob(this_path + '/*.wav')
		for file_path in tqdm(file_paths):
			file_entries = get_file_information(file_path)
			for file_entry in file_entries:
				csv_writer.writerow(file_entry)


def get_soxi_line(reg, input):
	return re.sub(reg, '', input) 


def get_file_intrinsic_information(file_path):
	info_line = re.compile('(.*?):(.+)')
	output = subprocess.check_output(['soxi', file_path]).split("\n")
	replace_header = re.compile('.*?: ')

	result = {}

	if len(output) >= 9:
		result = {
			'channels': get_soxi_line(replace_header, output[2]), #channels
			'sample_rate': get_soxi_line(replace_header, output[3]), #sample rate
			'precision': get_soxi_line(replace_header, output[4]), #precision
			'duration': re.sub('\s=.+$', '', get_soxi_line(replace_header, output[5])), #duration
			'bitrate': get_soxi_line(replace_header, output[7]), #bit rate
			'encoding': get_soxi_line(replace_header, output[8]) #encoding
		}
	else:
		print "ERROR: " + file_path
	return result


def get_file_extrinsic_information(file_path):	
	# regular expression: (path) (id) (side) (digg unit) (take) (notes)
	m = re.match('^(?:.+/)(.+?)-([ab])-(d\d+)-(t\d+)(?:-(.+))?.wav$', file_path)
	file_entry = {}
	if m:
		file_entry = {
			'path': path.abspath(file_path),
			'id': m.group(1),
			'side': m.group(2),
			'dig': m.group(3),
			'take': m.group(4),
			'notes': m.group(5),	
			'updated at (UTC)': time.strftime("%d %b %Y %H:%M:%S", time.gmtime(path.getmtime(file_path))),
			'size': get_size(path.getsize(file_path)),
			'md5': md5(file_path)
		}
	else :
		file_name_regex = re.match('^(?:.+/)(.+?).wav$', file_path)
		file_entry = {
			'path': path.abspath(file_path),
			'id': file_name_regex.group(1),
			'updated at (UTC)': time.strftime("%d %b %Y %H:%M:%S", time.gmtime(path.getmtime(file_path))),
			'size': get_size(path.getsize(file_path)),
			'md5': md5(file_path)
		}

	return file_entry


# from https://stackoverflow.com/questions/3431825/generating-an-md5-checksum-of-a-file
def md5(fname):
	hash_md5 = hashlib.md5()
	with open(fname, "rb") as f:
		for chunk in iter(lambda: f.read(4096), b""):
			hash_md5.update(chunk)
	return hash_md5.hexdigest()


def get_file_information(file_path):
	result = []
	file_extrinsic_information = get_file_extrinsic_information(file_path)
	file_intrinsic_information = get_file_intrinsic_information(file_path)
	
	# split file_extrinsic_information id by special character "_" and 
	# enter each id modified in the result
	ids = file_extrinsic_information['id'].split('_')

	for id in ids:
		result_line = dict(file_intrinsic_information, **file_extrinsic_information)
		result_line['id'] = id
		result.append(result_line)

	return result


# from https://stackoverflow.com/questions/1094841/reusable-library-to-get-human-readable-version-of-file-size
def get_size(num, suffix='B'):
	for unit in ['','K','M','G','T','P','E','Z']:
		if abs(num) < 1024.0:
			return "%3.2f%s%s" % (num, unit, suffix)
		num /= 1024.0
	return "%.1f%s%s" % (num, 'Yi', suffix)

if __name__ == "__main__":
	main()
